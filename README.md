# Emotion Recognition

## ðŸ“Œ Project Overview
This project implements an **Emotion Recognition model** using the [CREMA-D dataset](https://github.com/CheyneyComputerScience/CREMA-D) (Crowd-sourced Emotional Multimodal Actors Dataset).  
The goal is to classify human emotions from speech and visual features, extracted from audio and image files from the dataset.

### Workflow
- Data loading and preprocessing
- Feature extraction (e.g., spectrograms, HOG, LBP)
- Dimensionality reduction of Mel Spectrogram features using PCA. 
- Exploratory Data Analysis (EDA) on both audio and image modalities
- Building the classifier (Linear Regression-based classification)
- Evaluation of model performance

---

## 
